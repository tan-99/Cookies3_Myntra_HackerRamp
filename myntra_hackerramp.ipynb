{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTikE0zH1Z0q",
        "outputId": "ec876e47-5957-4fc4-f877-aa9402053ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ACGPN'...\n",
            "remote: Enumerating objects: 161, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 161 (delta 20), reused 18 (delta 18), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (161/161), 302.85 KiB | 4.81 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n",
            "/content/ACGPN\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n",
            "Cloning into 'Self-Correction-Human-Parsing-for-ACGPN'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 769 (delta 103), reused 94 (delta 94), pack-reused 567\u001b[K\n",
            "Receiving objects: 100% (769/769), 3.89 MiB | 15.21 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n",
            "Cloning into 'U-2-Net'...\n",
            "remote: Enumerating objects: 822, done.\u001b[K\n",
            "remote: Counting objects: 100% (334/334), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 822 (delta 312), reused 299 (delta 299), pack-reused 488\u001b[K\n",
            "Receiving objects: 100% (822/822), 30.71 MiB | 25.69 MiB/s, done.\n",
            "Resolving deltas: 100% (391/391), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/levindabhi/ACGPN.git\n",
        "%cd ACGPN\n",
        "\n",
        "!pip install ninja\n",
        "import os\n",
        "\n",
        "!mkdir Data_preprocessing/test_color\n",
        "!mkdir Data_preprocessing/test_colormask\n",
        "!mkdir Data_preprocessing/test_edge\n",
        "!mkdir Data_preprocessing/test_img\n",
        "!mkdir Data_preprocessing/test_label\n",
        "!mkdir Data_preprocessing/test_mask\n",
        "!mkdir Data_preprocessing/test_pose\n",
        "!mkdir inputs\n",
        "!mkdir inputs/img\n",
        "!mkdir inputs/cloth\n",
        "\n",
        "!git clone https://github.com/levindabhi/Self-Correction-Human-Parsing-for-ACGPN.git\n",
        "!git clone https://github.com/levindabhi/U-2-Net.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# For segmentation mask generation\n",
        "url = 'https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH'\n",
        "output = 'lip_final.pth'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "%cd U-2-Net\n",
        "!mkdir saved_models\n",
        "!mkdir saved_models/u2net\n",
        "!mkdir saved_models/u2netp\n",
        "!gdown --id 1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy -O saved_models/u2netp/u2netp.pth\n",
        "!gdown --id 1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ -O saved_models/u2net/u2net.pth\n",
        "import u2net_load\n",
        "import u2net_run\n",
        "u2net = u2net_load.model(model_name = 'u2netp')\n",
        "%cd ..\n",
        "\n",
        "!mkdir checkpoints\n",
        "gdown.download('https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx', output='checkpoints/ACGPN_checkpoints.zip', quiet=False)\n",
        "%cd checkpoints\n",
        "!unzip ACGPN_checkpoints\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "nxLMw0nK1sGl",
        "outputId": "236dc2a1-4e6f-4146-9ca5-f80e0cb56300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
            "From (redirected): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH&confirm=t&uuid=b6d8d3e5-d22d-4e69-b792-174697885eb6\n",
            "To: /content/ACGPN/U-2-Net/lip_final.pth\n",
            "100%|██████████| 267M/267M [00:06<00:00, 40.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'U-2-Net'\n",
            "/content/ACGPN/U-2-Net\n",
            "mkdir: cannot create directory ‘saved_models’: File exists\n",
            "mkdir: cannot create directory ‘saved_models/u2net’: File exists\n",
            "mkdir: cannot create directory ‘saved_models/u2netp’: File exists\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2netp/u2netp.pth\n",
            "100% 4.68M/4.68M [00:00<00:00, 83.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
            "From (redirected): https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ&confirm=t&uuid=06fc27ce-8767-4a9f-9296-52f12a3daa4b\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2net/u2net.pth\n",
            "100% 176M/176M [00:03<00:00, 55.7MB/s]\n",
            "...load U2NEP---4.7 MB\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7099f64beb76>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mu2net_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mu2net_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mu2net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu2net_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'u2netp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ACGPN/U-2-Net/u2net_load.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"...load U2NEP---4.7 MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU2NETP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m                 \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    250\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-v3-stable-linux-amd64.zip -O /content/ngrok-v3-stable-linux-amd64.zip\n",
        "!unzip /content/ngrok-v3-stable-linux-amd64.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMqi3C4Q18HC",
        "outputId": "296caa22-0e17-411d-bc73-10b4ecc365f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-15 15:45:49--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-v3-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 52.202.168.65, 54.161.241.46, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘/content/ngrok-v3-stable-linux-amd64.zip’\n",
            "\n",
            "/content/ngrok-v3-s 100%[===================>]  13.28M  51.3MB/s    in 0.3s    \n",
            "\n",
            "2024-07-15 15:45:50 (51.3 MB/s) - ‘/content/ngrok-v3-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n",
            "Archive:  /content/ngrok-v3-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the base_dataset.py file\n",
        "file_path = '/content/ACGPN/data/base_dataset.py'\n",
        "\n",
        "\n",
        "# Step 1: Read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_contents = file.read()\n",
        "\n",
        "\n",
        "# Step 2: Replace 'transforms.Scale' with 'transforms.Resize'\n",
        "modified_contents = file_contents.replace('transforms.Scale', 'transforms.Resize')\n",
        "\n",
        "\n",
        "# Step 3: Write the modified contents back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_contents)\n",
        "\n",
        "\n",
        "print(\"File has been modified.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Path to the test.py file\n",
        "file_path = '/content/ACGPN/test.py'\n",
        "\n",
        "\n",
        "# Step 1: Read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_contents = file.read()\n",
        "\n",
        "\n",
        "# Step 2: Replace 'np.float' with 'float'\n",
        "modified_contents = file_contents.replace('np.float', 'float')\n",
        "\n",
        "\n",
        "# Alternatively, if you want to use 'np.float64', replace as follows:\n",
        "# modified_contents = file_contents.replace('np.float', 'np.float64')\n",
        "\n",
        "\n",
        "# Step 3: Write the modified contents back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_contents)\n",
        "\n",
        "\n",
        "print(\"File has been modified.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Path to the test.py file\n",
        "file_path = '/content/ACGPN/test.py'\n",
        "\n",
        "\n",
        "# Step 1: Read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_contents = file.read()\n",
        "\n",
        "\n",
        "# Step 2: Replace 'np.int' with 'int'\n",
        "modified_contents = file_contents.replace('np.int', 'int')\n",
        "\n",
        "\n",
        "# Alternatively, if you prefer to use 'np.int32', use the following:\n",
        "# modified_contents = file_contents.replace('np.int', 'np.int32')\n",
        "\n",
        "\n",
        "# Step 3: Write the modified contents back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_contents)\n",
        "\n",
        "\n",
        "print(\"File has been modified.\")\n",
        "\n",
        "\n",
        "# Path to the pix2pixHD_model.py file\n",
        "file_path = '/content/ACGPN/models/pix2pixHD_model.py'\n",
        "\n",
        "\n",
        "# Step 1: Read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_contents = file.read()\n",
        "\n",
        "\n",
        "# Step 2: Replace 'np.float' with 'float'\n",
        "modified_contents = file_contents.replace('np.float', 'float')\n",
        "\n",
        "\n",
        "# Alternatively, if you prefer to use 'np.float64', use the following:\n",
        "# modified_contents = file_contents.replace('np.float', 'np.float64')\n",
        "\n",
        "\n",
        "# Step 3: Write the modified contents back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_contents)\n",
        "\n",
        "\n",
        "print(\"File has been modified.\")\n",
        "\n",
        "\n",
        "# Optional: Create a backup of the original file\n",
        "backup_file_path = file_path + '.bak'\n",
        "with open(file_path, 'r') as original_file:\n",
        "    with open(backup_file_path, 'w') as backup_file:\n",
        "        backup_file.write(original_file.read())\n",
        "\n",
        "\n",
        "print(f\"Backup created at {backup_file_path}\")\n",
        "\n",
        "\n",
        "# Path to the pix2pixHD_model.py file\n",
        "file_path = '/content/ACGPN/models/pix2pixHD_model.py'\n",
        "\n",
        "\n",
        "# Step 1: Read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_contents = file.read()\n",
        "\n",
        "\n",
        "# Step 2: Replace 'float64' with 'np.float64'\n",
        "modified_contents = file_contents.replace('float64', 'np.float64')\n",
        "\n",
        "\n",
        "# Alternatively, if you want to use 'float', replace as follows:\n",
        "# modified_contents = file_contents.replace('float64', 'float')\n",
        "\n",
        "\n",
        "# Print part of the modified contents to verify changes\n",
        "print(modified_contents[:1000])  # Print first 1000 characters\n",
        "\n",
        "\n",
        "# Step 3: Write the modified contents back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_contents)\n",
        "\n",
        "\n",
        "print(\"File has been modified.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egu2pxZm36hN",
        "outputId": "0ddded66-a41c-4fc8-ada2-154cf79af5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File has been modified.\n",
            "File has been modified.\n",
            "File has been modified.\n",
            "File has been modified.\n",
            "Backup created at /content/ACGPN/models/pix2pixHD_model.py.bak\n",
            "import numpy as np\n",
            "import torch\n",
            "import os\n",
            "from torch.autograd import Variable\n",
            "from util.image_pool import ImagePool\n",
            "import torch.nn as nn\n",
            "\n",
            "import cv2\n",
            "from .base_model import BaseModel\n",
            "from . import networks\n",
            "import torch.nn.functional as F\n",
            "\n",
            "NC = 20\n",
            "\n",
            "\n",
            "def generate_discrete_label(inputs, label_nc, onehot=True, encode=True):\n",
            "    pred_batch = []\n",
            "    size = inputs.size()\n",
            "    for input in inputs:\n",
            "        input = input.view(1, label_nc, size[2], size[3])\n",
            "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
            "        pred_batch.append(pred)\n",
            "\n",
            "    pred_batch = np.array(pred_batch)\n",
            "    pred_batch = torch.from_numpy(pred_batch)\n",
            "    label_map = []\n",
            "    for p in pred_batch:\n",
            "        p = p.view(1, 256, 192)\n",
            "        label_map.append(p)\n",
            "    label_map = torch.stack(label_map, 0)\n",
            "    if not onehot:\n",
            "        return label_map.float().cuda()\n",
            "    size = label_map.size()\n",
            "    oneHot_size = (size[0], label_nc, size[2], size[3])\n",
            "    input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
            "File has been modified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OUE-1dn4DAe",
        "outputId": "1f39c474-d331-4da6-faef-bad70c4d8144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the caffemodel in Google Drive\n",
        "source_path_caffemodel = '/content/drive/MyDrive/pose_iter_440000.caffemodel'\n",
        "# Path where you want to store it in Colab\n",
        "destination_path_caffemodel = '/content/ACGPN/pose/pose_iter_440000.caffemodel'\n",
        "\n",
        "# Copy the file from Google Drive to Colab directory\n",
        "shutil.copy(source_path_caffemodel, destination_path_caffemodel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MB5IQoxJ4ckt",
        "outputId": "8bae2f39-367e-4690-96fe-12b9f3bb5263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ACGPN/pose/pose_iter_440000.caffemodel'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok authtoken 2jGjH0DyGix4fhpi1hzHAr2PyCV_5gsPN9oAWDyhuwnKWSjQT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbv0ZhE1_s1",
        "outputId": "3946c999-d8b8-4802-dad0-ecca31f69817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Authenticate Ngrok\n",
        "ngrok.set_auth_token(\"2jGjH0DyGix4fhpi1hzHAr2PyCV_5gsPN9oAWDyhuwnKWSjQT\")\n",
        "\n",
        "# Start Ngrok tunnel\n",
        "http_tunnel = ngrok.connect(5000)\n",
        "print(\"Public URL:\", http_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WRBC2gz2OHt",
        "outputId": "0758f080-4c0c-4f8c-848e-6441d4a5d305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-07-15T15:48:44+0000 lvl=warn msg=\"ngrok config file found at both XDG and legacy locations, using XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://e33c-34-139-160-43.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, send_file, jsonify\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import u2net_run\n",
        "from predict_pose import generate_pose_keypoints\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "input_dir = '/content/ACGPN/inputs'\n",
        "output_dir = '/content/ACGPN/results/test/try-on'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def empty_folder(folder_path):\n",
        "    if not os.path.isdir(folder_path):\n",
        "        raise NotADirectoryError(f\"The path {folder_path} is not a directory or does not exist.\")\n",
        "    for item in os.listdir(folder_path):\n",
        "        item_path = os.path.join(folder_path, item)\n",
        "        if os.path.isfile(item_path):\n",
        "            os.remove(item_path)\n",
        "        elif os.path.isdir(item_path):\n",
        "            shutil.rmtree(item_path)\n",
        "    print(f\"Folder {folder_path} has been emptied.\")\n",
        "\n",
        "def process_images():\n",
        "    img_path = os.path.join(input_dir, 'img', sorted(os.listdir(os.path.join(input_dir, 'img')))[0])\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize((192, 256), Image.BICUBIC)\n",
        "    img.save(os.path.join('Data_preprocessing/test_img', '000001_0.png'))\n",
        "\n",
        "    cloth_path = os.path.join(input_dir, 'cloth', sorted(os.listdir(os.path.join(input_dir, 'cloth')))[0])\n",
        "    cloth = Image.open(cloth_path)\n",
        "    cloth = cloth.resize((192, 256), Image.BICUBIC).convert('RGB')\n",
        "    cloth.save(os.path.join('Data_preprocessing/test_color', '000001_1.png'))\n",
        "\n",
        "    u2net_run.infer(u2net, 'Data_preprocessing/test_color', 'Data_preprocessing/test_edge')\n",
        "\n",
        "    !python3 Self-Correction-Human-Parsing-for-ACGPN/simple_extractor.py --dataset 'lip' --model-restore 'lip_final.pth' --input-dir 'Data_preprocessing/test_img' --output-dir 'Data_preprocessing/test_label'\n",
        "\n",
        "    pose_path = os.path.join('Data_preprocessing/test_pose', '000001_0_keypoints.json')\n",
        "    generate_pose_keypoints('Data_preprocessing/test_img/000001_0.png', pose_path)\n",
        "\n",
        "    with open('Data_preprocessing/test_pairs.txt', 'w') as f:\n",
        "        f.write('000001_0.png 000001_1.png')\n",
        "\n",
        "    !python test.py\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    empty_folder('inputs/img')\n",
        "    empty_folder('inputs/cloth')\n",
        "\n",
        "    person_image = request.files['person_image']\n",
        "    cloth_image = request.files['cloth_image']\n",
        "\n",
        "    person_image.save(os.path.join('inputs/img', 'person.jpg'))\n",
        "    cloth_image.save(os.path.join('inputs/cloth', 'cloth.jpg'))\n",
        "\n",
        "    process_images()\n",
        "\n",
        "    return 'Images uploaded successfully!'\n",
        "\n",
        "@app.route('/result', methods=['GET'])\n",
        "def get_result():\n",
        "    result_image_path = os.path.join(output_dir, '000001_0.png')\n",
        "    if os.path.exists(result_image_path):\n",
        "        return send_file(result_image_path, mimetype='image/png')\n",
        "    else:\n",
        "        return jsonify({'error': 'Result not ready'}), 404\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9SkKKKLET7V",
        "outputId": "3524c95c-c8da-48ba-c358-ba40712bf0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder inputs/img has been emptied.\n",
            "Folder inputs/cloth has been emptied.\n",
            "Generating mask for: 000001_1.png\n",
            "Saving output at Data_preprocessing/test_edge/000001_1.png\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00,  1.55it/s]\n",
            "File saved at Data_preprocessing/test_pose/000001_0_keypoints.json\n",
            "?\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "continue_train: False\n",
            "data_type: 32\n",
            "datapairs: test_pairs.txt\n",
            "dataroot: Data_preprocessing/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "fineSize: 512\n",
            "gpu_ids: [0]\n",
            "how_many: 1000\n",
            "input_nc: 3\n",
            "isTrain: False\n",
            "label_nc: 20\n",
            "loadSize: 512\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 1\n",
            "n_blocks_global: 4\n",
            "n_blocks_local: 3\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: label2city\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "serial_batches: True\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "Data_preprocessing/test_label label\n",
            "Data_preprocessing/test_img img\n",
            "Data_preprocessing/test_edge edge\n",
            "Data_preprocessing/test_edge edge\n",
            "Data_preprocessing/test_mask mask\n",
            "Data_preprocessing/test_mask mask\n",
            "Data_preprocessing/test_colormask colormask\n",
            "Data_preprocessing/test_colormask colormask\n",
            "Data_preprocessing/test_color color\n",
            "Data_preprocessing/test_color color\n",
            "# Inference images = 1\n",
            "latest_net_U.pth\n",
            "latest_net_G1.pth\n",
            "latest_net_G2.pth\n",
            "latest_net_G.pth\n",
            "/content/ACGPN/models/pix2pixHD_model.py:227: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
            "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4343: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "Saving 000001_0.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/Jul/2024 16:09:52] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Jul/2024 16:09:53] \"GET /result HTTP/1.1\" 200 -\n",
            "WARNING:pyngrok.process.ngrok:t=2024-07-15T16:10:03+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-01e35550-925a-4ef8-873a-af13ae2f51dd acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxMDBKc33mO9",
        "outputId": "6e1ca980-2507-487e-a58d-a3e5c16ab06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ]
    }
  ]
}